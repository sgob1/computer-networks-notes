\documentclass[10pt]{book}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
%\usepackage[document]{ragged2e}
\usepackage{microtype}
\usepackage{notomath}
%\usepackage{CharisSIL}
\usepackage[usefilenames,RMstyle={Text, Text},SSstyle={Text,Bold},TTstyle={Text,Semibold},DefaultFeatures={Ligatures=Common}]{plex-otf} %
\usepackage[all]{nowidow}
\usepackage{graphicx}
\usepackage{svg}
\usepackage[pdfa]{hyperref}
\usepackage{color}
\usepackage{setspace}
\usepackage{parskip}
\usepackage[a4paper, inner=4.0cm, outer=5.0cm]{geometry}
\usepackage{listings}
\definecolor{dkgreen}{rgb}{0.1,0.5,0.1}
\definecolor{greengray}{rgb}{0.517,0.761,0.404}
\definecolor{orange}{rgb}{0.717,0.274,0.105}
\definecolor{blue}{rgb}{0.164,0.317,0.600}
\definecolor{background}{rgb}{0.990,0.990,0.990}
\lstset {
    frame=lrtb,
	language=java,
	aboveskip=0.7cm,
	belowskip=0.2cm,
	showstringspaces=false,
	columns=flexible,
	basicstyle={\small\ttfamily},
	numbers=none,
	backgroundcolor=\color{background},
	numberstyle=\tiny\color{dkgreen},
	keywordstyle=\color{blue},
	commentstyle=\color{greengray},
	stringstyle=\color{orange},
	breaklines=true,
	breakatwhitespace=true,
	tabsize=3
}

\newtheorem{thm}{Teorema}
\setlength{\tabcolsep}{0.5em} % for the horizontal padding
{\renewcommand{\arraystretch}{1.35}% for the vertical padding

\usepackage{fancyhdr}


\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE,RO]{\leftmark}
%\fancyhead[RE,LO]{Programmazione Avanzata}
%\fancyfoot[CE,CO]{\leftmark}
\fancyfoot[LE,RO]{\thepage}

\renewcommand{\headrulewidth}{1pt}
%\renewcommand{\footrulewidth}{1pt}

\usepackage{titlesec}
\titleformat{\part}[display]
{\Huge\bfseries\sffamily}{}{10pt}{\center{ Parte \thepart\ \ \\ \ \ }}
%\titleformat{\chapter}[display]
%{\huge\bfseries}{}{0pt}{\thechapter\ \ \--\ \ }
\titleformat{\section}[display]
{\Large\bfseries\sffamily}{}{0pt}{\medskip\thesection\ \ \textasciitilde \ \ }
\titleformat{\subsection}[display]
{\large\bfseries\sffamily}{}{0pt}{\medskip\thesubsection\ \ \textasciitilde \ \ }

\begin{document}
%\setmonofont[Scale=.85]{Fira Code Retina}
\setsansfont{IBM Plex Sans}


\include{cn-titlepage}
\setstretch{1.35}
\setlength{\headsep}{30pt}
\setlength{\footskip}{40pt}
\setlength{\marginparsep}{20pt}
\setlength{\marginparwidth}{50pt}
%\title{Computer Networks 2 and Introduction to Cybersecurity}
%\author{Marco Sgobino}
%\maketitle
\tableofcontents

\part{Transmission Control Protocol internals}

\chapter{TCP Basis}

\section{Recap}
TCP is a procotol that has the following remarkable properties,

\begin{enumerate}
	\item it is \emph{connection-oriented}: before transmitting data, a
		connection must be established \--- this is different to what
		IP protocol does in network layer, since in IP protocol there
        lies no concept of connection, and messages are exchanged under the
        paradigm of \emph{packet switching}\footnote{In telecommunications,
        packet switching is a method of grouping data into packets that are
    transmitted over a digital network. Packets are made of a header and a
payload. Data in the header is used by networking hardware to direct the packet
to its destination, where the payload is extracted and used by an operating
system, application software, or higher layer protocols. Packet switching is
the primary basis for data communications in computer networks worldwide. };
	\item it is \emph{reliable}: it assures all segments are correctly
		delivered through use of \emph{ACK} mechanism, and \textbf{at
		most once} \--- again, this is different to IP layer, since IP
        packets are just sent one after the other, unreliably, and there is no
        guarantee that they will be delivered, let alone in their correct
        ordering;
	\item it offers a \emph{sliding window} mechanism for congestion control
		and stream control. This assures read and send buffers are
		well-optimized in both sender and receiver \--- this feature is
		much important since it allows fine-tuning the connection and
		avoiding waste of resources;
	\item it is \emph{byte-oriented}: the byte stream is fragmented into
		multiple segments, and composed again after getting to
		destination \--- in this manner, huge payloads can be reliably
		delivered in multiple segments, each one having the correct
		order to the application. Application has the necessary information
		to easily reconstruct the correct ordering of the acquired 
		information.
\end{enumerate}

Ultimately, TCP allows creating connections between application processes,
offering multiple services to the upper layers. Connections are possible thanks
to the four above characteristics of the TCP layer.

\subsection{Sockets}

The TCP makes use of \emph{sockets} abstraction as a way of serving data to the
above application layer. The logical structure is the following one: there are
two entities, the client and the server. The client first authenticates to the
server; the server then opens a connection and the client executes the
subsequent send-receive loop. Both server and client need to create a
\emph{socket} $s$ (a UNIX-like file abstraction), that can be used to send and
receive data. Client connect $s$ to \texttt{IP-srv}, \texttt{port-srv}, while
the server operates a similar procedure on its own sockets. Each socket is then
bound to a specific IP address and a specific \emph{port number}, according to
the just-created connection specifics.

The communication takes place on $s$ by means of an application protocol, with
applications exchanging data each other. The connection is said to be
\emph{reliable}: losses and packet loss are carefully managed by the TCP
protocol, and segments\footnote{\emph{Segments} refer to the particular kind of
package that TCP protocol exchange. Usually, in literature one could find the
term package referring to TCP segments; while this is not fully correct, it may
be acceptable when there is no ambiguity.} are collected in the very same order
as they are sent.

A very simplified pseudo-code at client's side for TCP is as follows,

\begin{verbatim} int s; s := socket(...); 
connect(s, IP-srv, port-srv,...); 
...
send (s, msgl, ...); 
... 
msg2 := receive(s,...); 
... 
\end{verbatim}

where the notation \emph{...} denotes possibly code in between two
instructions. In the above code, a client wants to send data to a remove server
having a specific IP address and a port number. The client first creates a
socket, then connects it to the server IP address and to the corresponding port
number. After connection has been established, the client can subsequently
invoke \texttt{send()} to command TCP layer to deliver desired data to the
other end. To the very same socket, data can be received as well: by invoking
\texttt{receive()} the client can successfully retrieve eventual data sent by
the server. Socket acts as an \emph{abstraction} for the application layer, for
which a socket can be simply thought as a \textbf{data sink} or \textbf{data
source}.

At server side, the logical structure is quite different. A server creates
a socket \texttt{s1}, chooses a port number to bind to that socket (usually a
standard one), then it declares \emph{willingness to accept connections} on
\texttt{s1}, and finally it awaits for connection requests on \texttt{s1}. Upon
receiving a connection request, the server handles it by creating
\emph{another} socket \texttt{s2} and managing the connection on this newly
generated socket, this time with a different port number. 

Basically, it creates two different sockets: the first is kept alive to accept
new connections, and the second one is created on-demand, and it is required to
actually manage the connection. A \emph{different} socket is required for each
connection. A server usually remains on \emph{sleep} until a connection is
requested, awaiting a request on the main socket.

\begin{verbatim} 
s1 := socket(...);
bind(s1, portsrvm ...);
listen(s1,...);
s2 := accept(s1,...); // another socket
... 
msg1 := receive(s2,...);
...
send(s2,msg2,...);
... 
\end{verbatim}

Details of the above code largely depend on the platform on which the server is
operating.

\section{TCP Implementation}

TCP layer is built \emph{on top} of the IP layer. Since there are many differences
between TCP and IP, set aside their abstraction layer, TCP should be properly
built to manage IP differences and quirks. 

IP protocol operates between \emph{nodes}: it is \emph{connectionless},
\textbf{unreliable}, and is \emph{message-oriented}. The \textbf{Maximum
Transmission Unit} size of an IP packet is $MTU = 64KB$: this implicitly means
a TCP segment can never be greater than the MTU, because a TCP segment is
carried \emph{inside} an IP packet.

In TCP, communication happens to be \textbf{bidirectional}, with a pattern that
depends on the application protocol. The send\----receive patterns heavily depends
on the application itself \-- browser-related send\----receive sequences are
very different from, let's say, an e-mail client send\----receive sequence.
There is no guarantee that two different application protocols will exchange a
similar amount and kind of TCP messages, let alone the very same ones.

As already mentioned, TCP layers communicate between themselves in terms of
\emph{segments}. A segment is a single \emph{message between TCP layers}, and
contains a \emph{TCP header} and \--- eventually \--- data, that is said to be
\emph{payload}. The difference between information in header and information in
payload is that the first one is strictly required by the TCP layer, while the
second one is information required by the application layer. The latter may be
absent in some segments.

Payload in fact can either be $0$ bytes long or carry some information (wanted
by the application layer). \emph{A TCP segment must be small enough to fit in a
single IP packet}, hence IP header and TCP segment size should be no greater
than $64KB$, the MTU of an IP packet.

Since a packet is composed by a IP header, whose payload is a TCP segment, and the
TCP segment is in turn composed by a TCP header, followed by eventual
application data, the shape of a packet plus its segment can be summarized as
follows,

\begin{verbatim}
| IP header | TCP header |  Payload ***  |
\end{verbatim}

Usually, IP header size is usually $20$ bytes, as well as TCP
header that is $20$ bytes. The IP datagram can be greater up to $64KB$, with
the first $40$ to $50$ bytes reserved to headers. Thus,

\begin{verbatim}
| IP header | TCP header |  Payload ***  |
   20 byte     20 byte        greater
\end{verbatim}

Segments can carry portions of the original data. For instance, in a video
stream many, many segments should be sent to client in order to carry enough
information and let application layer reconstruct the video correctly. For
this reason, in application layer, one huge application message could correspond to
\emph{many segments} in TCP layer, in \textbf{both} directions. At TCP
level multiple segments are usually required in order to send a single
`big' application-level message.

Basically, this means that while for the application layer a single
\texttt{send()} may suffice to send an entire file or all the information
required, from the TCP layer's point of view many and many segments may be
required, typically many more than the number of \texttt{send()} commands
invoked by the application (at least, an number of them equal to the
\texttt{send()} invocation should be sent).

\subsection{The connection state}

TCP takes care of creating \emph{connections} between processes. There would be
no actual TCP data exchange without an established connection. Connections do
possess their own \emph{state}, which fundamentally and univocally describes a
connection. It is enough to represent each connection with their \texttt{<id>}
and \texttt{<state>}, with the \texttt{<id>} field that contains essentially
$4$ informations,
\begin{enumerate}
    \item the \texttt{local IP} address;
    \item the \texttt{local port} number;
    \item the \texttt{remote IP} address;
    \item the \texttt{remote port} number.
\end{enumerate}

Four and only four informations are required: the IP address and the
port number of each connection's endpoint.

Each connection is then associated to a \texttt{state}, that serves as a
description of the actual state in which the connection lies. The state of the
connection describes precisely the condition in which the connection lies (is
it running? is it closed?).

Information regarding a TCP connection must reside in the packet and in the segment
header, so each received segment can be sorted out and managed properly. IP
addresses are extracted from the IP header, while port numbers are extracted
from TCP header, thus it suffices to look at the IP packet plus the TCP header.

Information in header is not sufficient: each endpoint must keep track of the
connection with a \emph{state variable}. The connection <state> includes
information on the \textbf{Maximum Segment Size} (MSS), which is the maximum
size of the \emph{data part} of a segment that the other part is willing to
receive. The MSS is negotiated upon connection opening \--- this value is, in
practice, identical in both direction and \textbf{not arbitrary}. In most
cases and for historical reasons, there are only $2$ possible values that
depend whether the connection:

\begin{itemize}
    \item \emph{lies on different networks} (connection through internet), MSS
        is $536$ bytes (MTU=576), that is the maximum segment size that can fit
        in the smallest possible packet \-- historically this was the most
        reliable option;
    \item \emph{lies on the same network} (connection through ethernet), MSS is
        $1460$ bytes (MTU=1500), which corresponds to ethernet MTU minus the IP
        header and TCP header \-- this is a good choice in order to fit to a
        single ethernet frame.
\end{itemize}

The core idea is that each segment must be \emph{sufficiently small} to fit in
one packet along the full path, \emph{in order to prevent fragmentation}. In
fact, by transmitting larger segments one could end up with fragmented
segments, with no real advantage and many disadvantages.

\subsection{IP and TCP header structure}

\begin{figure}[h]
    \centering
    \includegraphics[ width=1.2\linewidth, height=\textheight, keepaspectratio]{./pics/tcp/ipHeader.png}
    \caption{Header of an IP packet. Source: Wikipedia.}
    \label{fig:ipHeader}
\end{figure}

Figure~\ref{fig:ipHeader} shows the structure of an IP packet. Essentially,
\begin{description}
    \item[Version, 4 bit] The first header field in an IP packet is the four-bit version field.
        For IPv4, this is always equal to $4$;
    \item[Internet Header Length (IHL), 4 bit] The IPv4 header is variable in size due to
        the optional 14th field (options). The IHL field contains the size of
        the IPv4 header, it has 4 bit that specify the number of 32-bit words
        in the header. The minimum value for this field is 5, which
        indicates a length of $5 \times 32 b = 160 b = 20 B$. As a 4-bit
        field, the maximum value is 15, this means that the maximum size of the
        IPv4 header is $15 \times 32 \mbox{ bit } = 480 \mbox{ bit } = 60 \mbox{ bytes }$.;
    \item[Differentiated Services Code Point (DSCP), 6 bit] Originally defined as the
        type of service (ToS), this field specifies differentiated services
        (DiffServ) per \texttt{RFC 2474}. Real-time data streaming makes use of the
        DSCP field. An example is Voice over IP (VoIP), which is used for
        interactive voice services;
    \item[Explicit Congestion Notification (ECN), 2 bit] This field is defined in \texttt{RFC
        3168} and allows end-to-end notification of network congestion without
        dropping packets. ECN is an optional feature available when both
        endpoints support it and effective when also supported by the
        underlying network;
    \item[Total Length, 16 bit] This 16-bit field defines the entire packet size in
        bytes, including header and data. The minimum size is 20 bytes (header
        without data) and the maximum is $65535 B$. All hosts are required
        to be able to reassemble datagrams of size up to $576 B$, but most
        modern hosts handle much larger packets. Links may impose further
        restrictions on the packet size, in which case datagrams must be
        fragmented. Fragmentation in IPv4 is performed in either the sending
        host or in routers. Reassembly is performed at the receiving host;
    \item[Identification, 16 bit] This field is an identification field and is
        primarily used for uniquely identifying the group of fragments of a
        single IP datagram. Some experimental work has suggested using the ID
        field for other purposes, such as for adding packet-tracing information
        to help trace datagrams with spoofed source addresses, but \texttt{RFC 6864}
        now prohibit any such use;
    \item[Flags, 3 bit] A three-bit field follows and is used to control or
        identify fragments. They are (in order, from most significant to least
        significant):
        \begin{itemize}
            \item bit 0: Reserved; must be zero;
            \item bit 1: Don't Fragment (DF);
            \item bit 2: More Fragments (MF).
        \end{itemize}
        If the DF flag is set, and fragmentation is required to route the packet,
        then the packet is dropped. This can be used when sending packets to a host
        that does not have resources to perform reassembly of fragments. It can
        also be used for path MTU discovery, either automatically by the host IP
        software, or manually using diagnostic tools such as ping or traceroute.
        For unfragmented packets, the MF flag is cleared. For fragmented packets,
        all fragments except the last have the MF flag set. The last fragment has a
        non-zero Fragment Offset field, differentiating it from an unfragmented
        packet;
    \item[Fragment offset, 13 bit] This field specifies the offset of a particular
        fragment relative to the beginning of the original unfragmented IP
        datagram in units of eight-byte blocks. The first fragment has an
        offset of zero. The $13$ bit field allows a maximum offset of $(213 –
        1)\times 8 = 65528 B$, which, with the header length included $(65528 +
        20 = 65548 B)$, supports fragmentation of packets exceeding the maximum
        IP length of $65535 B$;
    \item[Time to live (TTL), 8 bit] An eight-bit time to live field limits a
        datagram's lifetime to prevent network failure in the event of a
        routing loop. It is specified in seconds, but time intervals less than
        1 second are rounded up to 1. In practice, the field is used as a hop
        count—when the datagram arrives at a router, the router decrements the
        TTL field by one. When the TTL field hits zero, the router discards the
        packet and typically sends an ICMP time exceeded message to the
        sender. The program traceroute sends messages with adjusted TTL values
        and uses these ICMP time exceeded messages to identify the routers
        traversed by packets from the source to the destination;
    \item[Protocol, 8 bit] This field defines the protocol used in the data portion of
        the IP datagram. IANA maintains a list of IP protocol numbers as
        directed by \texttt{RFC 790};
    \item[Header checksum, 16 bit] The 16-bit IPv4 header checksum field is used
        for error-checking of the header. When a packet arrives at a router,
        the router calculates the checksum of the header and compares it to the
        checksum field. If the values do not match, the router discards the
        packet. Errors in the data field must be handled by the encapsulated
        protocol. Both UDP and TCP have separate checksums that apply to their
        data. When a packet arrives at a router, the router decreases the TTL
        field in the header. Consequently, the router must calculate a new
        header checksum;
    \item[Source address, 32 bit] This field is the IPv4 address of the sender of the
        packet. Note that this address may be changed in transit by a network
        address translation device;
    \item[Destination address, 32 bit] This field is the IPv4 address of the receiver
        of the packet. As with the source address, this may be changed in
        transit by a network address translation device;
    \item[Options, up to 288 bit] Options are largely unused, and may be considered harmful by
        some router. This is the portion of the IP header that is variable in
        size.
\end{description}


\begin{figure}[h]
    \centering
    \includegraphics[ width=1.0\linewidth, height=\textheight, keepaspectratio]{./pics/tcp/tcpHeader.png}
    \caption{Header of a TCP segment.}
    \label{fig:tcpHeader}
\end{figure}

On the TCP header, instead, Figure~\ref{fig:tcpHeader} shows the header
structure,

\begin{description}
    \item[Source port, 16 bit] Identifies the sending port;
    \item[Destination port, 16 bit] Identifies the receiving port;
    \item[Sequence number, 32 bit] Will be covered later, its role is to keep
        track of the sequence of segments;
    \item[Acknowledgment number, 32 bit] Same as the above, but keeps track
        of the \emph{successfully delivered} packages;
    \item[Data offset, 4 bit] Specifies the size of the TCP header in 32-bit
        words. The minimum size header is 5 words and the maximum is 15 words
        thus giving the minimum size of 20 bytes and maximum of 60 bytes,
        allowing for up to 40 bytes of options in the header. This field gets
        its name from the fact that it is also the offset from the start of the
        TCP segment to the actual data;
    \item[Reserved, 3 bit] For future use and should be set to zero;
    \item[Flags, 9 bit] Contains $9$ flags, with some important ones:
        \begin{description}
            \item[URG] Indicates that the Urgent pointer field is significant;
            \item[ACK] Indicates that the Acknowledgement field is significant. All
                packets after the initial SYN packet sent by the client should have
                this flag set;
            \item[PSH] Push function. Asks to push the buffered data to the
                receiving application;
            \item[RST] Resets the connection;
            \item[SYN] \emph{Synchronize sequence numbers}. Only the first packet sent
                from each end should have this flag set. Some other flags and
                fields change meaning based on this flag, and some are only valid
                when it is set, and others when it is clear;
            \item[FIN] Last packet from sender.
        \end{description}
    \item[Window size, 16 bit] The size of the \emph{receiving window}. It is
        the number of window size units that the sender of this very segment is
        willing to receive. Useful in flow control;
    \item[Checksum, 16 bit] Checksum for error\--checking;
    \item[Urgent pointer, 16 bit] If the URG flag is set, then this 16-bit
        field is an offset from the sequence number indicating the last urgent
        data byte;
    \item[Options, variable 0–320 bit, in units of 32 bit] Various options.
\end{description}

\section{TCP Architecture}

\subsection{TCP bears an unpredictable and unrepeatable nature}

TCP carries many different implementations, depending mostly on OS of choice.
Several variants of its components have been written, with many of them largely
optional, or deprecated. As already mentioned, execution flow at application
level works independently and unpredictably with respect to the TCP-level flow:
when an application sends something, multiple TCP packages are exchanged;
how many and when they are sent is \emph{not predictable}.

TCP works by first copying data that should be sent in a buffer, and then send
them later.

The sequence of bytes is first copied to a buffer (sliding window) and the
\texttt{send()} function is, for example, invoked \--- the exact time in which a
segment is sent is \textbf{unpredictable}, \textbf{unrepeatable} and depends on
many things, over which the application has little to no control. This means
that application cannot \emph{deterministically predict} the exact time in
which the transmission will occur \--- instead, the TCP layer will deliver the
payload at a specific time determined by the protocol\footnote{However, also on
TCP layer there is a level of unpredictability. Many more effects can concur: for
instance, the Operating System may not be ready to send a segment, or may be
busy with other resources. These situation will cause delay in sending
information, even from the TCP layer's point of view.}.

On TCP, various \emph{events} can induce a transmission of data:

\begin{itemize}
    \item application invokes \texttt{send()} \--- in this case, the data in
        send's call argument will be inserted into the proper transmission
        buffer, and it will be transmitted somewhere in the (possibly
        immediate) future; 
    \item application invokes \texttt{receive()} \--- this way, we will see in
        detail that the TCP protocol will send a \emph{response} that
        \emph{acknowledges} the receipt of a segment, for the other party's
        sake;
    \item TCP layer \emph{receives a segment} \--- the same as above;
    \item a \emph{timeout} occurs \--- TCP layer will inform the other party of
        this;
\end{itemize}

Each of the above will trigger a transmission either immediately or
\emph{withing a maximum predefined time} (in the case of a timeout, for
instance). When a TCP layer ``is touched'' from above or below, \textbf{it reacts
by transmitting a segment}. Transmission should occur \emph{even if there is no
useful data to transmit} (e.g. if the transmission buffer is empty) \-- in that
case, a segment will only carry the header, which has information useful to the
protocol itself. Basically, regardless of the presence of data in the
transmission buffer the TCP protocol will exchange vital protocol information.
Protocol information is, in fact, necessary to keep the connection alive and
well-performing.

Upon transmission, TCP may deliver a varying number of bytes, ranging from
empty up to a number of bytes \emph{larger than Maximum Segment Size} ($536$ in
Internet network, $1460$ for same Ethernet network). Since huge payloads cannot
fit into a single segment with a predefined MSS, the TCP protocol
\emph{fragments} them before delivery, resulting in \emph{multiple segments
delivered in sequence}. TCP protocol will try its best to send as many segments
as possible, for efficiency's sake: it is not uncommon that $2$ or $3$ segments
are initially delivered before receiving the other party's response.

\begin{table}[ht]
\centering
\begin{tabular}{cc}
CPU Cycle & $0.3 ns$ \\
Main Memory Access (DRAM) & $120ns$ \\
SSD & 50-150 $\mu s$ \\
HHD & $10 ms$ \\
Internet, San Francisco to New York & $40ms$
\end{tabular}
\caption{Some interesting metrics. Notice the order of magnitudes differences
between CPU cycles and network delays. This table highlights the fact that
bytes cannot be injected through the internetwork at full\--speed: suppose one
has a $100MB$ transmission buffer that is delivered across just $1ms$ \--
injected throughput would be $100 \cdot 10^6 \cdot 8 b/(10^{-3} s)$, which
yields an astonishing $8 \cdot 10^{11} b/s = 800 Gb/s$, unsustainable for most
of internetworks.}
\label{tab:SomeMetrics}
\end{table}
\bigskip

The TCP protocol starts with \emph{slowly sending segments, increasing the exchange
speed as the time goes on}. Acceleration mainly depends on the timing of
\emph{received} segments, by looking at the metrics of confirmation packets
from receiver. As the sender acknowledges that the receiver is able to keep up
with the increasing transmission speed, it raises up the delivery speed. Basically, TCP layer adapts its speed to $2$ determining factors,
\begin{itemize}
    \item the receiver's speed at processing packages;
    \item the internetwork's capability of deliver packages.
\end{itemize}

As we will see in following chapters, the first factor is handled by the
\textbf{Flow Control} algorithm, while the second one is kept under control by
the \textbf{Congestion Control} system.

\subsection{How an application asks for data to be transmitted}

The system call \texttt{send()} processes the data transmission through the
network. The \texttt{send} function passes a memory buffer contained in
application space (address, length), and copies bytes from transmission memory
buffer in application space to transmission memory buffer in TCP layer (called
\textbf{TX-buffer}).

\begin{lstlisting}
public void write(byte[] b)
	throws IOException
\end{lstlisting}

Send is first invoked by application level, whose execution flow is completely
independent from the TCP layer's one. Buffer at application layer is then
copied to the TCP transmission buffer, to be sent immediately or later. New
invokations of \texttt{send()} will copy data in TCP buffer \textbf{after} the
data that is already present.

Invoking \texttt{send()} \textbf{does not guarantee} any immediate
transmission: all it does is pushing application data into TX-buffer to be sent
in future. TCP will then \emph{independently} establish the proper moment and
way to transmit data present in transmission buffer.

Suppose now one has to send $N$ bytes with $K$ consecutive \texttt{send()}
invocations. How many segments will be exchanged? How many transmission events?

First and foremost, the number of segments will not depend on $K$, since no
matter how many times \texttt{send()} is invoked, the end result will be to simply
insert those $N$ bytes in the TX-buffer, because the sole effect of
\texttt{send()} is to insert the passed number of bytes into the TX-buffer,
triggering a transmission. As a first approximation, the number of transmitted
segments will roughly be $$\mbox{\#transmitted } = \frac{N}{MSS} + 1,$$ with
the last segment $+1$ smaller than the previous ones. Things, however, can go
wrong and be much more complex due to packet loss and retransmissions. Recall
that for all these reasons, the exact number is neither predictable nor
repeatable.

\subsection{Retrieving data from TCP}

Data retrieval occurs with another system call, \texttt{receive()}. System call
\texttt{receive()} is quite similar to the \texttt{send()} call: both
receiver's TCP layer and Application layer execution flows act independently to
each other, and receiving buffer is not guaranteed to contain any data.

When data reaches the receiver, the data is copied into the receiving buffer
(\textbf{RX-buffer}). The receiving buffer stores all received bytes and is
flushed only when the application invokes \texttt{receive()}. The function
\texttt{receive()} copies (at least a portion of) the receiver buffer into the
application buffer by means of passing a buffer with known \emph{address} and
\emph{length}. Function \texttt{receive()} copies bytes without exceeding the
size of the buffer (\emph{length}) and it \textbf{returns} how many bytes have
been copied into the provided buffer. As argument, \texttt{receive()} also
takes the number of bytes to fetch from the TCP receiving buffer. Basically,
\texttt{receive()} needs to accept a buffer to which data should be copied, its
length (in C length information is \textbf{not} intrinsic to arrays) and the
expected number of bytes to be retrieved.

There are three possible outcomes for the \texttt{receive()} call:

\begin{itemize}
    \item the \emph{receive buffer is empty}: the application is suspended and
        the process is put to sleep until some data is available;
    \item \emph{more than \texttt{length} bytes are available}: a
        \texttt{length} number of bytes is fetched and delivered to the
        application as soon as possible. More \texttt{receive()} calls are
        needed to retrieve all data and empty the RX-buffer;
    \item \emph{less than \texttt{length} bytes are available}: all available
        bytes are copied as soon as possible, since they are less than the
        maximum deliverable value. The single \texttt{receive()} call will not
        yield all requested bytes, and more calls should be used.
\end{itemize}

Basically, each time a number of bytes is requested, TCP will provide \emph{up
to} that number of bytes. The application is held back only in the case when there
is no data available.

Now with an example: let a buffer have length equal to $800$ bytes. Suppose
\texttt{receive()} is invoked in the following scenarios,
\begin{enumerate}
    \item in the first scenario, there are $600$ bytes in the RX-buffer. Upon
        \texttt{receive()} call, all $600$ bytes are delivered to the
        application. The RX-buffer is now empty;
    \item in the second scenario, there are $1000$ bytes in the RX-buffer. Upon
        \texttt{receive()} invocation, only $800$ of the $1000$ bytes are saved
        into the buffer \-- $200$ bytes will remain into the RX-buffer;
    \item in the third scenario, there is \emph{no data} in the TX-buffer.
        Application is suspended until there is data to retrieve. Suppose $500$
        bytes are collected in the RX-buffer \-- they will be immediately saved
        into the buffer provided by the application, and the application will
        retrieve them. RX-buffer is now emptied.
\end{enumerate}


\section{Sequence numbers}

IP protocol is \emph{unreliable} (packets can be lost, duplicated, or delivered
in different order from which they were sent). To overcome this huge
shortcoming, each data byte is implicitly identified by a $32$ bit
\textbf{sequence number}\marginpar{\small\textsf{Sequence number}}. A sequence number is a label for each transmitted and
received byte, so that both correct ordering and amount of data can be properly
determined. The association is \emph{implicit} \--- the sender applies a
sequence number to a segment, and the receiver uses that information to
reconstruct the original order of segments. This way, segments are
reconstructed even if they show up haphazardly, and the data can be assembled
as it originally was.

There are many variables\marginpar{\small\textsf{snd.User}} involved in sequence numbers. \texttt{snd.User} is the
variable carrying the value of the next byte the \textbf{application} will
send. The variable \texttt{snd.Next}\marginpar{\small\textsf{snd.Next}} carries the value of the next byte that
the \textbf{TCP layer} will transmit \--- its value is contained in the TCP
header (initial byte of the sequence, of course). Basically, \texttt{snd.User}
refers to the next byte that will be filled by the invocation of
\texttt{send()}, while \texttt{snd.Next} is the next byte yet to transmit by
the TCP layer. The sequence number of application level must be computed from
other information. 

The variable \texttt{snd.Next} is carried in the TCP segment header, in
\emph{sequence number} space (16 bit).

In short,

\begin{itemize}
	\item \texttt{snd.Next} is the boundary between transmitted data and
		yet-to-transmit data;
	\item \texttt{snd.User} is the boundary between in TX-buffer data (data
        sent by application) and not-yet-associated bytes, the free space in
        the buffer.
\end{itemize}

Upon sending a segment, the \emph{sequence number} will be inferred from the
\texttt{snd.Next} variable, and will be the \emph{next byte the other endpoint
expects}.

\begin{figure}[b]
        \centering
        \includegraphics[ width=1.2\linewidth, height=\textheight, keepaspectratio]{./pics/tcp/TxBuffer.png}
	\caption{TX-Buffer and its flags \texttt{snd.Ack}, \texttt{snd.Next} and \texttt{snd.User}.}
        \label{fig:TxBuffer}
\end{figure}

From the receiver's point of view, the variable \texttt{rcv.Next} is the
boundary between content of RX-buffer and not-yet-received data (right boundary
of the data currently in buffer). The variable \texttt{rcv.Next} is similar to
the variable \texttt{rcv.Next} in the sense that it points at the next byte yet
to receive. Only packets having the \emph{expected sequence number} are collected
and brought into the buffer.

There is a special case where some segment carries new parts of information and
sequence numbers that are not collected, with a portion of them already
collected: in that case the incoming segment will still be collected, with
duplicated bytes thrown away. There may be two reasons for packet duplications:
either IP layer duplicates them, or the TCP sender retransmits them because it
thought they were lost. In order to be able to retransmit packets, TCP stores
all sent data in buffer until acknowledgement has been received, since they
could be retransmitted in the immediate future.

\begin{itemize}
    \item \texttt{rcv.Next} points at the next byte that is not yet being
        received;
    \item \texttt{rcv.User} points to the next byte to be received by the
        application. After \texttt{receive()} invokation by the application,
        all bytes that have been successfully delivered to the application can
        now be safely deleted.
\end{itemize}

\begin{figure}[b]
        \centering
        \includegraphics[ width=1.0\linewidth, height=\textheight, keepaspectratio]{./pics/tcp/RxBuffer.png}
    \caption{RX-buffer and its flags. Notice that RX-buffer only uses two flags
    instead of three (no ACK flag needed). Indeed, there is no need to keep
track of sent ACKs: they will be sent as soon as segments are acquired.}
        \label{fig:RxBuffer}
\end{figure}


Each TCP layer has \textbf{both} TX-buffer and RX-buffer. Sequence numbers in
the two directions are independent each other, and they will increase as much
as there is new data incoming from a direction.

Each and every segment is accepted only if it contains \emph{new} data: that
is, when the sequence number is the expected one \emph{or} when the segment
contains novel sequence numbers. 

Each segment also carries information on the \emph{length} of its payload. This
allows the receiver to efficiently reconstruct the segment, in order to compute
the ending sequence number, and not only the starting sequence number.

An important remark is that \textbf{sequence numbers are 32-bit integers}.
Therefore, the sequence numbers can only go from $0$ to $2^{32} - 1$, so there
may be \emph{wrap-arounds} in an overflow-like fashion. TCP should internally
handle these comparisons in a proper manner.

\section{Handling duplicates and loss}

IP is an unreliable protocol. This means that \emph{packets can be loss}.
Necessary mechanisms are two,

\begin{itemize}
    \item the \textbf{retransmission}, or when a segment is regarded to be
        sent again;
    \item the \textbf{acknowledgement}, which is a kind of \emph{notification
            of receipt}, that is sent by the receiver in order to make the
            other party sure that it has received and collected the data sent
            to it.
\end{itemize}

\emph{Acknowledgements} are a mechanism that assures receipt of a message by
means of \emph{notifications}. Every header of a segment contains the sequence
number of \texttt{snd.Next}. Every segment also \emph{carries an information
regarding the bytes that are received}: the \textbf{acknowledgement number},
which tracks the state of the RX-buffer by following the pointer
\texttt{rcv.Next}. This way, having both sequence number and acknowledgement
number, one can successfully track the state of a TCP connection. Upon sending
a TCP segment, both sequence number and acknowledgement number are delivered,
so that the receiver can reconstruct the state of the sender RX-buffer.

Basically, sequence number tracks the bytes a party \emph{has sent}, while
acknowledgement number tracks the bytes a party \emph{has successfully
received}. Both informations must be exchanged at every delivered segment.

A fifth variable\marginpar{\small\textsf{snd.Ack}} is thus needed: \texttt{snd.Ack}, which \emph{points to the
byte in TX-buffer before which any transmitted byte had been acknowledged}.
This variable is only increased upon receiving data (for instance, upon
receiving a sequence with a greater ACK number from the sender). Since it has
been safely collected, all data before \texttt{snd.Ack} pointer can be
forgotten. 

Acknowledgements mechanism is crucial to a TCP connection, in order to
provide \textbf{reliability} to a connection. Therefore, transmission of
acknowledgements is always necessary even if TX-buffer is empty. In that case, no
payload will be transmitted, and only protocol information is sent (increasing
acknowledgement number).

An important note is that \texttt{snd.Ack} is only updated when the received
sequence number \texttt{segment.ack} is \emph{greater} than the value in
\texttt{snd.Ack} \-- that is, when new data are correctly received.

For this reason one can say that the sequence number tracks \texttt{snd.Next},
while the acknowledgement number tracks \texttt{rcv.Next}. However, the
sequence number will be at the value of the \emph{first} sent byte, that is the
first byte the receiver is expecting.

For instance, suppose the receiver has successfully received $130$ bytes from a
sender: its \texttt{rcv.Next} points to the $130$th element in the RX-buffer.
In order to inform the sender, all the new incoming segments from the receiver
will carry $130$ as sequence number (it points to the $131$st element). Upon
receiving such packets, the sender will successfully interpret the sequence
number, and set the \texttt{snd.Ack} variable to $130$: all the data prior to
$130$ can be safely discarded.

Data bytes between pointers \texttt{snd.Ack} and \texttt{snd.Next} is said to
be \textbf{in flight} data. These bytes have been transmitted but not yet
acknowledged, and are potentially eligible for retransmission.

The reason why acknowledgements are important is pretty straightforward: without
acknowledgements, there would be \textbf{no way for the sender to tell whether
sent data has been received or not}. This means that even though the receiver
has no data, acknowledgements are still required and should be properly sent.

In the end, acknowledgements are a crucial component of TCP, without them it
wouldn't be possible to provide either a reliable or a predictable connection,
with no chance of keeping track of actually and successfully delivered
information.


\section{Delayed Acknowledgement}

\emph{Delayed Acknowledgement} is a notorious TCP algorithm. Its core idea is
not to answer immediately with an acknowledgement, but to await some arbitrary
time interval $T$ that depends on the operating system. The algorithm is pretty
straightforward:

\begin{quote}
Upon receiving a segment, if delayed-ack timer $T$ has previously been set,
\emph{transmit immediately}. Else, set the delayed-ack timer $T$ to a specific
value.
\end{quote}

When receiving a packet, simply set a timer, and send the response segment
after timer expires. However, if you receive yet another segment before the
timer expires, then send immediately the response.

Delayed-ack timer value depends on the operating system:

\begin{itemize}
    \item RFC suggests $T = 500ms$;
    \item Windows has $T = 200ms$;
    \item Linux in general has $T = 40ms$;
    \item RHEL sets $T = 4ms$.
\end{itemize}

The reasoning is as follows: if there is not much data to transmit, it will be
likely that the timer $T$ will expire. Expiring timer means sending a packet
with the proper acknowledgement number \-- a strategy that guarantees that the
connection stays open and remains fresh. If the other part is sending a lot of
data, the contrary will be more likely to occur, breaking the awaiting. In
order to help the other part, acknowledges will be delivered as soon as a
\emph{second segment} is received. 

The core idea is to both help the other end and
minimize the number of segments to be sent: this is done by preventing to
respond with a segment whose sole purpose is to inform of acknowledged data
\emph{at each segment received}, while still answering with ACK information
even though there is little to no data received. In fact, a delay time $T$
assured to save sending some segments, a feature that historically was of a
crucial importance.

\section{Retransmissions}

The connection state includes three more actors, related to
\emph{retransmission}:

\begin{itemize}
    \item a \textbf{retransmission timer}, which counts the time interval until
        which the retransmission is held back;
	\item a variable that describes the \emph{duration of retransmission
        timer interval}, the \textbf{RTO (Retransmission Time-Out)};
    \item a \textbf{retransmission counter}, that counts how many
        retransmissions for a segment have been performed.
\end{itemize}

The \textbf{retransmission algorithm} is as follows:

\begin{quote}
    Upon transmitting segment S, \emph{if timer is not already set}, then the
    counter is cleared and set to $0$, with the timer set to the RTO value.
    At the beginning, then, a new counter is spawned and the timer is set to
    a value which is the RTO value.

    When an ACK is received, \texttt{snd.Ack} is updated to the maximum value
    between \texttt{snd.Ack} and \texttt{segment.Ack}. If \texttt{snd.Ack ==
    snd.Next}, the timer is switched off: the sent data has been received by
    the other party correctly and as expected.

    There may be occasions in which the timer expires, though.
    When timer expires, the \emph{counter is incremented} and if the counter
    has not yet reached a \texttt{MAX\_COUNT} value, the segment is
    retransmitted. However, this time the timer value is set to RTO but
    \texttt{RTO = 2 * RTO}, which is the double of the original value.
    \emph{Only in-flight data should be retransmitted} (and all of it after
    timer expires). Basically, data for which we are sure that it has been
    received should not be retransmitted in case the timer expires, and the
    sender should only focus on retransmitting not-yet-acknowledged data. At
    each retransmission, the RTO is doubled, and the retransmission counter is
    increased.

    When counter reached \texttt{MAX\_COUNT} value, an excessive number of
    retransmissions has been attempted, and connection is closed.

    Upon receiving an ACK for \textbf{all} the in-flight data, switch the timer
    off (that is, when \texttt{snd.Ack == snd.Next}).

    A particular condition is when an ACK arrives \emph{for only a portion} of
    the data that has been sent. In that case, the timer resets (the receiver
    has responded) to the RTO value, \emph{as if those still not-ACKed had been
    sent now}, and the sender awaits ACK for missing segments. This basically
    occurs when a partial ACK comes, and prevents unnecessary retransmissions.
\end{quote}

Exact\marginpar{\small\textsf{Choosing RTO}} timings of retransmissions are hard to predict. A sender is completely
blind if it does not receive any ACK: should it send again in-flight segments,
or should it wait a little bit more? In practice, how long should the timer be
set? Basically, a rule of thumb is that it should be ``slightly larger'' than
Round\----Trip Time. In order to do so, since RTT largely varies depending on
connections, time, and many other conditions, RTO is \textbf{dinamically updated}
by algorithms such as \emph{Jacobson algorithm}.

Regarding the maximum number of retransmissions\marginpar{\small\textsf{Max\_Count}}, value of \texttt{MAX\_COUNT}
largely depends on the operating system. For instance, Windows closes
connection after $5$ failed attempts, Linux after $15$. It is simple to realise
that there may be a lot of unnecessary retransmissions: the timer can, for
instance, run out too soon for the acknowledgement to reach the sender.
Unnecessary retransmissions are a waste of resources, and definitely a
fundamental problem. The reason could be one of those:

\begin{itemize}
    \item segments are \emph{lost}, retransmissions are necessary;
    \item there could be segments \emph{whose ACKs are lost};
    \item RTO was set to a \emph{too small value}.
\end{itemize}

Thus, RTO should be set to an appropriate value, since a too short value leads
to high overhead and possibly many unnecessary retransmissions, while a too
long value results in high latency and possibly a slow or non-responsive
connection. RTO value is basically a \emph{trade-off} between exhibiting few
retransmissions and having a fast and responsive connection. RTO should be set
\textbf{dinamically}: it should be slightly greater than the \emph{RTT}
(Round-Trip-Time), an idea from Jacobson algorithm. This is of a crucial
importance for TCP to work. Initial RTO value is heuristical, and varies from
one OS to another. Linux and Window start from same value, macOS use a
different value, and so on.


\section{Multiple default gateways}

More default gateways could be added to a single node. Reasons to add more than
one default gateway all boil down to \emph{failure avoidance}. To know whether a
gateway has stopped working, a heuristic TCP algorithm tries to detect a
gateway failure:

\begin{quote}
    If the number of retransmissions is greater than \texttt{MAX\_COUNT}
    divided by 2, the \emph{connection} changes its default gateway (if
    possible). Moreover, if the number of connections that changed default
    gateway is greater than the number of open connections divided by 4, the
    \emph{IP layer} changes the default gateway as well. This last feature
    speeds up reconfiguration of early connections that still have to make some
    retransmission attemps.
\end{quote}

Basically, each connection can autonomously choose its own gateway, but the IP
layer is able to \textbf{force} any \--- new or already present \--- connection
to use a different default gateway. A connection that exceeds the total number
of retransmissions will change default gateway, and if $4$ or more connections'
default gateway switches are detected the IP layer will switch to a different
default gateway as well, forcing all newly created TCP connections to switch to
the new gateway.


\begin{figure}[h]
    \centering
    \includegraphics[ width=1.0\linewidth, height=\textheight, keepaspectratio]{./pics/tcp/timeSequenceTCP.png}
    \caption{Time plot of sequence numbers. Dots correspond to sent segments. Some retransmissions occur.}
    \label{fig:timeSequence}
\end{figure}

\section{Selective Acknowledgements}

Suppose that 4 segments are sent, and the second one has been lost: in this
case, the receiver got all segments except the second one, but it has
no way to inform the sender to retransmit only the second segment. Sending
ACK for only the first segment would result in unnecessary retransmission of
segments 3 and 4, which were instead correctly received. 

For this reason, the receive buffer could end up having some \textbf{gaps},
missing bytes that are supposed to be received. The solutions are
\textbf{Selective Acknowledgements} (SACK), a special kind of acknowledgements
that carry both \emph{left and right sequence number edges} of each
out-of-order \textbf{block} in RX-buffer, this way correctly informing the
other party of a \emph{specific} missing portion of the data, avoiding
unnecessary retransmissions. Selective Acknowledgements can selectively mark
which bytes should be transferred again, and only those.

SACK protocol must be \emph{supported by both members} of a connection in order
to be useful. The protocol is very convenient, since many segments can be lost
when a sender tries to deliver dozens of segments at once. This way, TCP can
achieve \emph{efficient handling} of the connection, minimizing the number of
unnecessary retransmissions.

In SACK\--supporting segments, a \texttt{TCP Option} field exist, in which both
\texttt{left edge} and \texttt{right edge} are inserted, and they allow for
correct data reconstruction after it has been lost, only for that portion
delimited by the two edges.

Of course, out-of-order segments could still lead to gaps in RX-buffer, causing
an unnecessary retransmission. In this case, unnecessary retransmissions are
unavoidable when an out-of-order segment reaches the receiver too late, after a
long time interval, since the receiver will send a SACK informing the sender of
the missing segment, while the very same segment arrives late. However, no
matter what, SACK is always convenient, since it reduces a lot the burden to
the sender for only missing segments are to be sent.

To optimize out-of-order gaps, \textbf{Fast retransmit} algorithm should be
adopted (not part of this course).

\section{Operating System TCP interrupts and the real TCP execution flow}

Upon packet arrival, a \emph{system interrupt} is sent. 

An operating system executes many concurrenct activities: application process, other networking processes, manages other system interrupts, and so on.

When a system interrupt is cast, the operating system will try its best to fetch data from the network physical device.

From the TCP point of view, after data comes from the operating system, he will
analyze the packet to sort it by \emph{looking at the connection table}, and
then it will \textbf{push in the input queue} the relative packet. The input
queue holds a certain amount of segments, stored in the order given by sequence
number.

When the TCP protocol decides it's time to process all segments in queue, it
deeply analyzses them, picks their payload, grabs their header information, and
processes all of them. After processing all segments in input queue, the buffer
is emptied.

Basically, TCP can never \textbf{immediately} process a segment upon arrival.
What it can do best, is to await some time, receive an amount of segments
depending on the operating system's load at that moment and many other factors,
and then process them altogether. Since many of them are processed at the same
time, only a single acknowledgement will be sent back to the sender.

Since there are \emph{many} different sources of randomness, let alone things
that are completely out of TCP's control (just think of connection's quality,
operating system's load, the other's end capabilities, packet loss,
send\----receive invocations), there is \textbf{no} single correct way for TCP
protocol to exchange a given amount of data with another party.

\chapter{Flow and Congestion Control}

To behave optimally, TCP needs to establish the correct amount of data that
should be exchanged in an interval of time.

Whenever TCP decides to transmit, there are three possible scenarios: 
\begin{enumerate}
    \item an empty segment is sent when there is no payload \-- that is the
        case, for instance, of acknowledgements or when timer expires;
    \item it transmits a single segment if payload data is smaller than MSS \--
        that is for few data;
    \item it transmits multiple segments if payload size exceeds MSS \-- that's
        the case for huge payloads.
\end{enumerate}

However, not all connections are equally good, and not all endpoints are fast
enough to cope with a sender's speed. A sender should not send more segments
than how many can be managed by the receiver \--- \emph{how many} is an upper
limit that should be dynamically changed.

The overall idea is the following one: TCP \textbf{starts slowly}, then
\emph{increases its transfer speed} according to the rate in which
acknowledgements are received. Since the interaction is bidirectional and
quite complicated, TCP implementation at sender's side tries to adapt to
both connection properties and receiver's side properties. 

As a general rule, the number of in-flight bytes is \emph{always lower than an
upper bound that is dynamically updated}, with an upper bound that is chosen
according to proper criteria. This means that TCP can automatically
\emph{adapt} to the peculiar characteristics of the connection and receiver's
speed.

In order to adapt the two different aspects of a TCP connection \-- the
\emph{connection quality} and the \emph{receiver's speed} \-- two bounds should
be adopted: the \textbf{Flow Control} and the \textbf{Congestion Control}. The
TCP layer will always send less data than the minimum between the two upper
bounds. 

The first algorithm constructs a bound in such a way that the capacity of the
receiver is always respected. Let an extremely fast computer send data faster
than a receiving, slow, computer. Slower computer has not enough speed to
collect all data that has been sent \--- the flow control algorithm lets the
sender speed adapt to the receiver speed by means of a \emph{send window}. 

The second algorithm, the congestion control, constructs a state variable
called \emph{congestion window}, whose goal is to \emph{model the maximum current
throughput of the network}. 

The number of in-flight bytes \emph{must be slower than both send window and
congestion window multiplied by MSS}, so that $$\mbox{in-flight} \leq
\min(\mbox{sndWin}, \mbox{congWin} \cdot \mbox{MSS}).$$ 

The mental model should be the following one: if the transmission buffer is
full of data, a number of in-flight bytes equal to the minumum of both
quantities should be sent, otherwise just send \texttt{snd.User - snd.Ack}
bytes (those still to send).

\section{Flow control}

Buffers cannot increase indefinitely: boundaries must be set in order to assure
system stability. In Linux kernel, buffer sizes are set upon compilation and are
then fixed; different operating systems may show other behaviors. In case data
cannot be pushed into the TX-buffer anymore because it is full, application
should be suspended. When the RX-buffer is full, packets have to be discarded
since they cannot be collected. Flow control will act to prevent this situation
by letting the sender know how much free space is available to the RX-buffer. 

The goal of flow control is to keep a fast transmitter from overrunning a
slower receiver.

Since application sends data much faster than ACK arrive, the TX-buffer could
end up being filled up by incoming segments. Suppose at receiver's side the
application invokes \texttt{receive()} much slower than incoming packages
speed. This way, the RX-buffer could fill up as well. To solve this issues,
application invokes \texttt{send()} only when TX-buffer is full, hence it is
put to sleep (blocked) until TCP gets proper ACK and advances \texttt{snd.Ack}
(when it has more free space).

TCP sender keeps track\marginpar{\small\textsf{Window Size}} of free space in other end's RX-buffer by looking at a
variable in header (WindowSize) that informs it of how much free space is
available, so that it can actually predict how much free space there is. When
it guesses that receiver's RX-buffer could have no space left, it stops
transmission and suspends the application. If the maximum window corresponds to
the size of a single segment, the protocol is called \textbf{stop-and-wait}
(that is \-- send a single segment, than wait for ACK). Larger windows enable
pipelining of multiple segments in a row, allowing far more efficient usage of
the connection.

Flow control algorithm\marginpar{\small\textsf{Sliding Window}} adopts the concept of \textbf{sliding window}. Each
segment header has a \texttt{WindowSize} field in the header that contains
\emph{how many free bytes are in the RX-buffer}. From sender's point of view,
\texttt{snd.winSize} contains the \emph{number of free bytes in RX-buffer of
the other side}.

The value is initially set to the receiver's entire buffer size, and it is
updated dynamically upon sending a segment. If a segment \texttt{S} carries
\texttt{S.Ack} that is greater or equal to \texttt{snd.Ack}, then the variable
\texttt{snd.winSize} is updated and set to \emph{S.windowSize}. The
\texttt{snd.WinSize} value ranges from $0$ to the buffer size at the receiver's
end.

Ultimately, the number of in-flight bytes must never exceed the number of bytes
in \texttt{snd.winSize} that are available in the RX-buffer. This means that
\texttt{snd.Next - snd.Ack} should \textbf{never} be greater than
\texttt{snd.WinSize}.

The end goal of TCP is to reach a number of in-flight bytes that is as close as
possible to the \texttt{snd.winSize} number of bytes, in order to optimize the
connection efficiently.

\begin{figure}[b]
    \centering
    \includegraphics[ width=1.0\linewidth, height=\textheight, keepaspectratio]{./pics/tcp/idealThroughput.png}
    \caption{Ideal throughput condition, in which the injected throughput is
    equal to M $\cdot$ MSS at each time $T$. In scheme, every timing is
considered constant, and the total time $T$ is the sum of the time in which all
the segments arrive at the receiver's end, the receiver's processing time and
the acknowledgement's time to arrive at the original sender's side.}
    \label{fig:idealThroughput}
\end{figure}

\clearpage


\section{Performance estimation}

From flow control, let's determine the maximum T-IN-TCP (input throughput) that can be obtained.
TCP is injecting some throughput into the network, and the amount of it is
controlled by the flow control algorithm. 

Suppose the receiver has a window size of $M \cdot MSS$, and the application
requesting data invokes \texttt{receive()} on a large buffer, such that the
buffer is emptied as soon as there is new data.

The best case one can get by flow control is $M \cdot MSS$ every RTT \--- this is
the case where the receiver's application empties the RX-buffer the moment the
segments arrive. Suppose in fact $M \cdot MSS$ bytes are sent at each round,
and no packet loss occurs: in that case, the receiver would immediately and
successfully grab all segments, sending the corresponding acknowledgment
answer.

In the case the application empties \emph{half} the buffer at periodic
intervals, the throughput would be the half as well, $M/2 * MSS$ every RTT.
After the first round, only half of the segments would be sent, since the
window size is indeed the half of the total one. 

If the entire buffer is emptied at once, but with a delay, or not aligned with
the receipt of segments, the throughput would be $M * MSS$ every RTT + $\Delta$
(more time than plain RTT). Combining all cases, one could get less than $M *
MSS$ data every \emph{longer} than RTT, depending on the parameters and the
circumstances of the network.

For the best case, it's important to recall that some important assumptions
have been made:
\begin{itemize}
    \item all intervals have same time duration $T$, as described in
        Figure~\ref{fig:idealThroughput};
    \item all the segments arrive together, or at least not after a time which
        is irrelevant or already counted in $T$.;
    \item acknowledgement arrives immediately, and not after a huge delay;
    \item receiver is perfect in managing segments, and provides an
        acknowledgment segment for the full data.
\end{itemize}

In every case, a greater RX-buffer will result in higher throughput, since
there is a proportionality between throughput and buffer size. Viceversa,
greater RTT will result in less throughput \--- LANs will have greater
throughput than WANs since they possess a lesser Round\----Trip Time. However,
in this formula the \emph{quality} of the network is not taken in account:
segments can be loss, especially when too many of them are injected through the
internet. For this reason, this much-optimistic model cannot be applied in
cases where the throughput is high (read \--- when RX-buffer is insanely huge).
Every time a retransmission is needed, \emph{detection and recovery} takes
place, and throughput becomes much smaller than the ideal case. This
phenomenon is much heavier as the RTT increases, since retransmissions are
harder to assess; Moreover, it is far from being predictable.

Another thing to consider is \emph{maximum network speed}. Injected throughput could
be \emph{even greater} than maximum network speed, in that case many segments
would be loss, resulting in a sub-optimal efficiency\footnote{This is solved by
Congestion control mechanism.}.

\subsection{Establishing size of RX-buffer}

Size of RX-buffer\marginpar{\small\textsf{Receiver's Buffer Size}} should have the following characteristic: the size should be
\emph{a multiple of MSS} \--- this is done to avoid leaving unused space at the
end of the buffer, since in the lucky case exactly a multiple of MSS will be
delivered. Non\--multiple sizes would make no sense.

However, the RX-buffer size is a \emph{trade-off} between greater ideal
throughput and lower throughput due to excessive retransmissions, and should be
chosen accordingly. Unexpectedly, $64KB$ are chosen; the value is OS-dependent.
The size is managed as if it were a multiple of MSS \--- when almost full,
pretend it is full and ignore last portion of buffer.

\begin{table}[ht]
\centering
\begin{tabular}{ccc}
    Flow control & Ethernet & Internet \\
    MSS  & $1460B$ & $536B$ \\
    RX-buffer & $64KB$ & $64KB$ \\
    number of segments in-flight & $44$ & $122$
\end{tabular}
\caption{Quantities involved in flow control, on Ethernet and Internet.}\label{tab:FlowControlQuantities}
\end{table}
\bigskip

\section{Sustainable throughput}

A sustainable throughput is indeed \textbf{not infinite}. After a certain injected
throughput \emph{T\_MAX}, the network bottlenecks and starts losing segments, exhibiting a
behavior that will lead to less performance. Thus, an optimal throughput should
be determined by and largely depends on \emph{connection quality}. Injected
segments are delivered at same speed only if the injected throughput is lower
than the maximum possible throughput, that is \emph{T\_MAX}.

\begin{figure}[b]
    \centering
    \includegraphics[ width=0.6\linewidth, height=\textheight, keepaspectratio]{./pics/tcp/networkCollapse.png}
    \caption{Network collapse after injecting a too-high throughput. Notice
        how injecting an even greater throughput will result in a \emph{lower}
        throughput.}
    \label{fig:networkCollapse}
\end{figure}


An excessive throughput \textbf{will} result in the following consequences:
\begin{itemize}
    \item packets exit \textbf{slower} than they entered;
    \item network's max sustainable throughput \emph{T\_MAX} will
        \emph{collapse} \--- this fenomenon is called \textbf{network
        congestion};
    \item network \textbf{will need some time to remove its congestion},
        with even worse behavior in the case the unsustainable throughput is
        maintained for a longer time.
\end{itemize}

Intuitively, a network collapse happens because networks possess different
maximum speeds, a quality that cannot be appreciated by TCP, let alone for
networks \emph{different} than the one in which the device is sending data.

It is then up to the TCP layer to detect issues during path, and slow down
segments injection. Routers commonly have a mechanism for packet queuing, which
can be filled up, resulting in packet discarding. Such discarded packets will
need a retransmission, leading in even lower performance. New injected segments
and packets will increase the time for which the queue is dissolved.

\section{Congestion control}

\textbf{Congestion Control} algorithm takes into account the quality of the
network, allowing the sender to adapt to it instead of making it collapse.

Suppose the bound of flow control is so large that congestion control is
predominant (which means snd.congWin*MSS < snd.WinSize). A congestion control algorithm
could try do infer the maximum throughput by looking at the RTT and calculating
MSS/RTT < T\_MAX. However, this is unfeasible, since it requires too much
rounds and tentatives to be inferred.

A second issue is that the quantity T\_MAX \emph{varies during time}:
it depends on nominal throughput of networks and routers, and on
\textbf{competition} of different injected throughputs in the network.
Basically, the competition in the network is \emph{unpredictable} and
\emph{time-varying}, allowing no fixed\--value algorithm to work.

\subsection{Actual algorithm}

Congestion control algorithm has some important components,
\begin{enumerate}
    \item the \emph{slow start};
    \item the \emph{congestion avoidance};
    \item the \emph{fast retransmit};
    \item the \emph{fast recovery};
\end{enumerate}

each one with several variants and many parameters to be properly set. We will
see \emph{Tahoe} algorithm, but the most used one is the \emph{Reno}
algorithm.
\begin{enumerate}
    \item The state variable \emph{CongestionWindow(t)} keeps track of a
        `virtual window' that is the actual quantity of data that can be
        injected through the network, and is initially set to a very small
        value (\emph{slow start principle}). Its value will increase whenever
        Acknowledgements are received in time \--- the network is assumed to be
        not congested. Upon retransmission (timeout expiration) the state
        variable is decreased a lot, and the network is assumed to be
        congested. 

    \item Another state variable, called \emph{SlowStartThreshold}, is
        a threshold under which \emph{CongestionWindow(t)} increases very fast,
        while above it the same state variable increases with a slower rate.
        Initial values of \emph{snd.congWin} and \emph{snd.ssThresh} are,
        respectively, $3$ MSS and $64KB$.

    \item Whenever an acknowledgement is received in time, the congestion
        window is increased. If the congestion window is lower than the
        threshold, increase fast with \textbf{slow start algorithm}; otherwise,
        increase slowly with \textbf{congestion avoidance} algorithm. 

    \item Upon retransmission (timeout expiration), the congestion window is
        reset to MSS and the threshold is set to the maximum value between $2$
        MSS and \texttt{(snd.Next - snd.Ack)/2} \--- that is, the maximum value
        between the double of MSS and the half of the in-flight bytes. The
        assumption upon retransmission is that the network is congested: this
        behavior is apparently inefficient, since \emph{many} concurrent causes may
        determine a packet loss \--- for instance, small RTO, network loss
        (e.g. WiFi) \--- but it's the best one can do to avoid any possible
        congestion. MARK slide 64

    \item The congestion window is increased by +MSS whenever an in-time ACK is
        received. Congestion avoidance algorithm does the same, but only upon
        receipt of \textbf{the last} in-time ACK (only if snd.congWin bytes are
        ACK'ed).
\end{enumerate}

The two algorithms increase the congestion window at \emph{much} different
speed. Slow start algorithm, despite its name, will \emph{double} the
congestion window each time an acknowledgement for all segments is received.
Congestion avoidance, instead, will increase the congestion window
\emph{linearly}, for which the window is increased by $1$ (single MSS) each
time an acknowledgement for all segments is received. The slow start will
provoke an exponential growth, while the congestion avoidance will provoke a
linear growth. 

\begin{figure}[hb]
    \centering
    \includegraphics[ width=0.7\linewidth, height=\textheight, keepaspectratio]{./pics/tcp/slowStartTypes.png}
    \caption{The two kinds of slow start evolutions. At left, exponential, at
    right, linear.}
    \label{fig:slowStartTypes}
\end{figure}



\subsection{Congestion control pattern in case of exponential growth}

Let's assume all segments are lost, and retransmission occurs after RTT (that
means, RTO is a good approximation of RTT). Let's also assume slow start
produces an exponential growth. Initial value of \emph{ssThresh\_start} is
$64KB$. Starting with threshold value below \emph{T\_MAX}, slow start will
yield an exponential growth; after some time, congestion avoidance will enter,
a segment loss will occur and the congestion window will be reset to half the
\emph{ssThresh\_start} original value. Initial threshold above \emph{T\_MAX}
will trigger a segment loss, and a reset of the threshold (without congestion
avoidance algorithm, that has not enough time to act). After the first segment
loss, threshold will be halved by setting it at half of the in-flight bytes,
and system will act as it started below the \emph{T\_MAX} throughput. The
``exponential, linear, drop'' pattern will occur \emph{forever}, and the three
phases (slow start, congestion avoidance, loss detection) will happen one after
the other.

\begin{figure}[hb]
    \centering
    \includegraphics[ width=1.0\linewidth, height=\textheight, keepaspectratio]{./pics/tcp/congestionControl.png}
    \caption{Congestion control and its dynamics. The pattern indefinitely
    repeats.}
    \label{fig:congestionControl}
\end{figure}


\clearpage

\subsection{Congestion control pattern in case of linear growth}

With same assumptions as above, but with slow start provoking a linear growth,
the pattern will be \emph{completely linear}, since no exponential growth
occurs. Basically, only the starting phase of each cycle will be different. The
end result in both patterns, however, is that the average \emph{T\_IN} value
will be \textbf{much} smaller than \emph{T\_MAX} \--- the TCP congestion
control cannot expoit internetwork capacity efficiently. Injected throughput
will always be lower than the maximum possible: the consequence, is that the
average throughput is lower than what the network could sustain, however, this
is very important in order to avoid network collapse and congestion.

\subsection{Fast retransmit in a nutshell}

Suppose $K$ segements are transmitted in a burst, and a single segment appears
to be lost. Resetting congWin to its minimum value is largely inefficient,
since only a single segment of the row has been lost. Another strategy could be
waiting for a timeout before resetting the congWin: the solution is inefficient
too, since waiting before retransmitting could lead to long breaks (how much to
wait? how to estimate a correct time interval?). The solution is to retransmit
\emph{immediately only} what appears to be the missing segment, and decrease
congWin \emph{but not} to its minimum value.

\subsection{Reasons of congestion control to slow down the network so much}

Intuitively, one would like to reach the maximum possible value for the
congestion window and the maximum throughput sustainable; however, they are
\textbf{unknown}. We can detect detect its value only after having injected an
excessive throughput, by detecing segment loss. An aggressive slow down occurs
at each detection of segment loss, in order to prevent the collapse of the
network. In fact, suppose many machines are injecting a throughput which is
closer to the maximum possible: in that case, if the network is congested,
\emph{it will require more time to return to its normal state}, because all
machines are insisting injecting throughputs close to unsustainable ones, and
removing congestion \emph{will} require larger time. Basically, this is a
heuristic way to avoid congestion on a network where multiple machines are
using transmission resources altogether.

In the end, congestion control strives to ensure \textbf{fairness}. Fairness is
the tendency of each competing TCP connection on a router to consume the same
fraction of the router capacity. Each connection, on the average, will consume
an equal fraction of router's capacity. However, today's standard impose
\textbf{node-level fairness}: this means that each node should have the same
amount of network capacity (thousands of TCP connections can be opened at the
same time from a single node). Note that UDP connections \emph{do not}
implement any flow or congestion control, and transmit at full-speed: they are
`selfish'.

\subsection{Estimating the average throughput}

Some assumptions should be made in order to compute average throughput:
\begin{itemize}
    \item slow start has \emph{linear growth};
    \item \emph{T\_MAX} is constant and in between $K\cdot MSS$ and$(K+1)\cdot MSS$;
    \item \emph{all} segments are lost at once (no wild retransmissions);
\end{itemize}

The average throughput that is injected is the average number of bytes in each
pattern, divided by $(K + 1)\cdot RTT$, that is FIXME
$$A_t = \frac{MSS\cdot \frac{K(K+1)}{2}}{(K+1)\cdot RTT} = \frac{MSS\cdot
K/2}{RTT}.$$ Thus, the injected throughput is the same one would obtain by
having a \emph{constant window} of $K/2 \cdot MSS$ size \--- on the average,
one can only get \textbf{half} of the maximum network throughput.

Slow start in exponential fashion makes this calculation quite more complex,
but we will genuinely assume a linear growth in all our calculations.

Another important scenario is not transmitting data after many RTTs. Without a
reset, one would use the last values that were determined by the congestion
control algorithm. In order to avoid bad performance, the sender \textbf{resets
both congWin and ssThresh} after a timeout. Basically, the approach is very
pessimistic and conservative, in order to avoid any kind of congestion in the
network.

\section{Interaction between flow control and congestion control}

The interaction between the two TCP control systems is not straightforward. At
connection opening, the bound imposed by congestion control is \emph{much}
tighter than the flow control one (2-4 MSS instead of $64KB$). Hence, at the
beginning the network will follow congestion control's dictated bounds \---
data arrives slowly.

After connection opening (steady-state), there are two possible cases:
\begin{itemize}
    \item T-MAX > T-FLOW-CONTROL \--- maximum network throughput is greater
        than maximum flow control throughput: in this case, the bottleneck is
        the \textbf{receiver's capacity}. The steady state throughput will be
        $\frac{M\cdot MSS}{RTT}$, while its connection opening transient
        throughput will be half of that value;
    \item T-MAX < T-FLOW-CONTROL \--- maximum network throughput is lower
        than maximum flow control throughput: in this other case, the
        bottleneck is the \textbf{internetwork}, and congestion window will go
        up and down, never reaching the value corresponding to the receiver's
        buffer size. The steady state throughput will be $\frac{K\cdot
        MSS}{2MSS}$.
\end{itemize}

Many variants of Congestion control have been developed. In particolar, there
are many families for different use-cases:
\begin{description}
    \item[congestion collapse] this class attempts to increase the average T-IN
        upon congestion collapse in a standard, wired internetwork connection;
    \item[wireless] this class strives to optimize correct non-wired environments, with algorithms tailored to environments with high network loss;
    \item [high-speed] this class is tailored to sustain very-high bandwidth
        connections (e.g. backbones), with \emph{high bandwidth-delay product}.
\end{description}


The latter is the case of backbones, with very-high bandwidth-delay product
\--- those are all the networks that, if TCP is left as default, will lead to
several minutes of connection start and gigabytes of data exchanged for the
sole goal of bringing the connection to full-speed. In order to optimize them,
several variants of TCP have been developed.

Suppose a sustainable throughput is $T_{MAX} = K \cdot MSS / RTT$, and suppose
the length of the first initialization period be $t_{init} = K \cdot RTT$.
Solving in $K$ leads to $$t_{init} = \frac{T_{MAX} \cdot RTT^2}{MSS}.$$ By
looking at the formula, one recognizes that the initial time has a squared
dependency over round-trip time, a direct proportionality over $T_{MAX}$ and is
inversely proportional to MSS. In all connections where both RTT and $T_{MAX}$
are large or extremely large, the initialization time could become relevant as
well as the sheer quantity of the data that is needed (more than $3$ minutes of
transient, more than 100GB transmitted).


\chapter{Connection opening}

\section{Sequence numbers initialization}

Upon connection opening, since they are not set to zero, each of the two sides
should agree to their initial sequence numbers. The ideal starting point is
that every \emph{snd} pointer should be set to the same value, as well as the
other party's \texttt{rcv} buffer. A first idea could be to simply send initial
segments in which \texttt{snd.Next} are specified in header. Special segments
carry a flag that denotes a connection request (from the client) and `ok' (from
the server). Both parties will set their initial \texttt{rcv} pointers to the
value read in the header from the other party. In reality, this first
implementation has many issues:
\begin{itemize}
    \item delayed duplicates from client may be received after a long time \---
        the server might uncorrectly believe another connection request is
        coming from the client (since there are port numbers, however, the new
        connection will be opened only in case the previous one has been
        closed);
    \item delayed duplicates from server may be received after a long time \---
        this way, an opening with wrong sequence numbers may occur.
\end{itemize}

The solution to the above problems, in which delayed packets may be
undistinguishable from not delayed ones: the ``\emph{cross your finigers}''
approach. The machines \emph{assume} that a predefined, maximum segment
lifetime exist \--- segments cannot exist after this supposed lifetime. Since
the assumption does not match reality, the algorithm execution does not provide
any guarantees. The lifetime in question is named \textbf{Maximum Segment
Lifetime (MSL)}, and it is arbitrarily set to $2 min$ ($120s$). After such MSL
time passed, the machine assumes that the segment will never reach it. This is,
in reality, wrong: IP do not have concept of time, and packets are discarded
only based off their number of \emph{hops}. 

\subsection{The three-way handshake protocol}

The sequence numbers are generated by the \textbf{ISN-generator} (initial
sequence number generator), a $32$-bit counter increased every $4\mu s$, even
when the node is switched off. Overflow will happen every 4-5 hours. The
generator is used to generate an initial sequence number from its current
value. A sequence number can used again at least after $4$ hours.

\begin{figure}[b]
    \centering
    \includegraphics[ width=1.0\linewidth, height=\textheight, keepaspectratio]{./pics/tcp/threeWayHandshake.png}
    \caption{The three-way handshake.}
    \label{fig:threeWayHandshake}
\end{figure}



The three-way handshake protocol (Figure~\ref{fig:threeWayHandshake} will begin
with sequence number initialization, from the ISN-generator (suppose it's $x$),
and send a SYN(seq=x)\footnote{SYN bit is a flag in TCP header that is always
zero, except in the first and second segments, and it is used only for
requesting connections.} packet to the server. The latter will answer with a
package such as SYN(SEQ=y, ACK=x+1). The client will then respond with a second
message, containing data and having sequence and acknowledgement numbers
(SEQ=x+1, ACK=y+1); now, connection has been established and both parties will
assume the connection is successfully opened. The client side will be sure that
no delayed duplicates are coming since $x$ should have come from a connection
which has been opened more than $4$ hours ago! The same reasoning happens from
the server side: any delayed duplicate should have been traveling for more than
$4$ hours. This protocol even protects in the case old duplicates are received:
that case, the other party will receive a wrong packet \--- for something they
did not request at all \--- and respond with a REJECT packet\footnote{RST is a
header flag as well as SYN, and it is used only to reject connections.}. The
client will respond with a REJECT(ACK=y).

A very unlucky case is where the server receives two delayed duplicates,
however, there is little to no chance that the ACK values are correct (and, in
that case, it would have traveled for more than $4$ hours, much more than MSL
value of 2 minutes). The same goes if the server receives a REJECT (it cannot
be a duplicate). The mechanism is shown in Figure~\ref{fig:threeWHduplicates}.

\begin{figure}[b]
    \centering
    \includegraphics[ width=1.0\linewidth, height=\textheight, keepaspectratio]{./pics/tcp/threeWHduplicates.png}
    \caption{Possible errors in TCP handshake. The TCP protocol and its
    sequence number system is designed to avoid unsolicited connection opening,
preventing the server to waste resources with no reason.}
    \label{fig:threeWHduplicates}
\end{figure}



RST segments are send in two cases,
\begin{itemize}
	\item unexpected rcv-seqnum in 3-way handshake;
    \item received segment for closed connection;
\end{itemize}
in those cases, send a RST segment with seqnum expected by peer.

In case the RST packet is legit (that is, when it carries the sequence number
the machine expects), then \textbf{close} the connection and \textbf{ignore}
rcv-segment.

\section{Interface between 3-way handshake and application layer}

Application layer just requests opening a connection. The TCP layer will handle
the connection opening with appropriate system calls. The system calls in sequence are

\begin{itemize}
	\item \texttt{socket};
    \item \texttt{bind};
    \item \texttt{listen(num, ...};
    \item \texttt{accept}.
\end{itemize}

System call listen has a \emph{num} in argument that tells \emph{how many
connections can be queued}, that is, the number of incoming SYN segments that
should be queued. Until listen call, no connection can be opened and the server
will respond with RST. Up to \emph{num} SYN segments can be accepted at the
same time \emph{before} invocation of accept and delivery of SYN-ACK packages.
Closing a connection happens with FIN flag. It is handled the same way as SYN
is, and where one party wants to close connection, sets FIN flag to $1$ and the
other party will respond with a FIN flag to $1$ as well.

This protocol can be abused to block a server with little to no effort. Attacks
whose goal is to prevent the target working are called \textbf{Denial of
Service} attack. An example of DoS attack is the \textbf{SYN-flood} attack.
SYN-flood attacks are very hard to detect and very cheap to operate. The idea
is to keep sending SYN segments so that server queue \emph{is always full}: the
effect will be that legitimate SYN requests from legitimate clients will be
discarded. Some variants even hide the IP-src by modifying it, in order to hide
attack origin. SYN-ACKs responses will be delivered to (fake) IP-src address.
Randomly forging IP-src addresses makes almost impossible to filter them out
with a firewall. SYN-flood attacks are cheap: for $128$ opened connections
every $3$ minutes, only $128\cdot 40 = 5120B every 180s = 228 bps$ bytes are
needed to the attacker to forge necessary packets. To forge $1280$ connections,
$1280\cdot 40 = 51200B every 3 m = 6826bps.$ A small cost of sending a packet
causes the listener to force a listening to a connection, a \textbf{much}
higher cost. By designing a new protocol, one would likely avoid spending
resources upon the first SYN, by operating \emph{statelessly} until the
initiation can demonstrate its legitimacy.

\chapter{TCP Reliability}

TCP a \emph{reliable} protocol. Reliable only means that data are received, in
order, and with no duplicates. However, application layer do not know how many
bytes are received by the other side of the connection. \texttt{send()} may
complete with no error, but no byte could be transmitted \--- no way to know
how many packages are actually delivered to the other party. Upon an error
taken during the $n+1$-th send invocation, there is no way to know if previous
messages were actually delivered or not. Despite TCP being reliable, there is
\textbf{no guarantee} that messages up to $n$-th were delivered and
transmitted. FIXME-6

The correct reasoning is that all bytes \emph{up to} $k$ are correctly
delivered, but one cannot know exact $k$ value. Regarding bytes delivered to
the application level at the other end, bytes were received by TCP layer up to
$k$ but probably $k - k'$ bytes \emph{are still to be delivered to the
application}. Only a portion of them, $k'$, have been delivered. Both $k$ and
$k'$ are \emph{unknown}. Only after \emph{receive} call, with all ACK correctly
received, one is sure that all previous data have been successfully delivered.
Upon receive error, one \textbf{cannot tell anything about the previous send
invocation}, since there is no clue that the packet has been received correctly
or not. Any of these scenarios might be the reason:
\begin{itemize}
    \item \emph{not received}: packet never received by the partner;
    \item \emph{not delivered}: packet arrived, but partner crashed before
        reply;
    \item \emph{delivered}: but not reaching, connection broke.
\end{itemize}

All these scenarios must be handled differently and correctly. Response to
failure should always be a correct failure handling and proper recovery from
damage, no matter the kind of it. Typical examples of error handling are:
\begin{enumerate}
	\item take an error;
    \item repeat;
    \item wait some time;
    \item send request again;
    \item until receiving a response.
\end{enumerate}

However, this approach is wrong, especially when dealing with financial
transactions, where same requests, multiple times, can lead to catastrofic
errors and wrong operations. Only read operations can be handled this way
effectively.



\part{Threat model}

\chapter{Understanding threat model}

TCP offers no authentication. It means that if in DNS the address has been
maliciously altered, a connection can be opened to the attacker's service
rather than to the legitimate one. Network attacker may be in control of the
router \--- he may switch DNS request and respond with fake responses. TCP
offers no integrity either. A network attacker might change what the machine
sends and receives \--- a communication may be altered by an entity that acts
in between the parties. An improved version of TCP, \textbf{TLS}, is available.
It acts on top of TCP and uses cryptography to protect integrity and offer
authentication.

Suppose now the client has been infected by malware \--- attacker can control
the client's behavior from remote, for example modifying web pages, opening
connections, attempting priviledge escalation. In this case, TLS does not
guarantee secrecy, integrity, authentication. 

Basically, it depends on \textbf{threat model}. The threat model is the set of
actions that we assume the attacker can execute. Reasoning about security of a
system without a well-posed threat model makes no sense.

Typical threat models involve the following scenarios, in increasing pessimism:
\begin{itemize}
    \item \textbf{Network attacker} \--- attacker can only operate in the
        network. He is able to observe and communicate. DoS and MITM attacks
        are usually what a network attacker can do;
    \item \textbf{Compromised endpoint} \--- attacker has compromised a node in
        the network with a malware;
    \item \textbf{Physical access} \--- attacker has physical access to an
        endpoint;
    \item \textbf{Insider/Supply chain} \--- attacker has access to portion of
        the software supply chain, e.g.\ libraries, infrastructure.
\end{itemize}


\end{document}
