\documentclass[a4paper, 11pt]{report}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{times}
\usepackage{graphicx}
\usepackage[pdfa]{hyperref}
\usepackage{color}
\usepackage{setspace}
\usepackage{parskip}
\usepackage[a4paper, inner=0.5cm, outer=0.5cm, lmargin=2.7cm, rmargin=2.7cm,
tmargin=2.0cm, bmargin=2.1cm]{geometry}
\usepackage{listings}
\definecolor{dkgreen}{rgb}{0.1,0.5,0.1}
\definecolor{greengray}{rgb}{0.32,0.57,0.32}
\definecolor{orange}{rgb}{0.96,0.42,0}
\definecolor{lightblue}{rgb}{0,0.28,0.95}
\definecolor{background}{rgb}{0.995,0.995,0.995}
\lstset {
	frame=tb,
	language=java,
	aboveskip=3mm,
	belowskip=3mm,
	showstringspaces=false,
	columns=flexible,
	basicstyle={\small\ttfamily},
	numbers=none,
	backgroundcolor=\color{background},
	numberstyle=\tiny\color{drkgeen},
	keywordstyle=\color{lightblue},
	commentstyle=\color{greengray},
	stringstyle=\color{orange},
	breaklines=true,
	breakatwhitespace=true,
	tabsize=3
}
\setlength{\parindent}{0pt}

\begin{document}
\setstretch{1.00}
\title{Computer Networks 2 and Introduction to Cybersecurity}
\author{Marco Sgobino}
\maketitle
\tableofcontents

\part{Low-Level Network Protocols}

\chapter{TCP}

\section{Brief recap of TCP}
TCP is a procotol that has the following properties,

\begin{itemize}
	\item allows \emph{connection between processes};
	\item is \emph{connection-oriented}: before transmitting data, a
		connection must be established;
	\item is \emph{reliable}: it assures all segments are correctly
		delivered through use of \texttt{ACK} mechanism, and \textbf{at
		most once};
	\item offers a \emph{sliding window} mechanism for congestion control
		and stream control. This assures read and send buffers are
		well-optimized in both sender and receiver;
	\item is \emph{byte-oriented}: the byte stream is fragmented into
		multiple segments, and composed again after getting to
		destination.
\end{itemize}

The logical structure is the following one. There are client and server. The
client first authenticates to the server, after that the server opens the
connection and client executes send-receive loop. Both server and client create
a \emph{socket} $s$, and the client connect $s$ to IP-srv, port-srv. The
communication takes place on $s$ by means of application protocol. It is
\emph{reliable}: no losses, no packet loss, packet arrive in the same order as
they are sent.

A very simplified pseudo-code for TCP is as following,

\begin{verbatim} int s; s := socket(...); 
connect(s, IP-srv, port-srv,...); 
...
send (s, msgl, ...); 
... 
msg2 := receive(s,...); 
... 
\end{verbatim}

The logical structure at server side is quite different. A server creates
socket $s1$, chooses a port number to bind to that socket, then it declares
willingness to accept connections on $s1$, and finally it awaits for connection
requests on $s1$. Server remains on \emph{sleep} until a connection is
requested.

\begin{verbatim} 
s1 := socket(...);
bind(s1, portsrvm ...);
listen(s1,...);
s2 := accept(s1,...); // another socket 
... 
msg1 := receive(s2,...);
...
send(s2,msg2,...);
... 
\end{verbatim}

In TCP, communication is \emph{bidirectional}, with a pattern that depends on
the application protocol.

The send-receive patterns depend on the application itself \--- browser
send-receive sequences are very different from, let's say, an e-mail client
send-receive sequence.

\subsection{TCP Implementation}

IP operates between \emph{nodes}. It is \emph{connectionless},
\textbf{unreliable}, and is \emph{message-oriented}. The Maximum Transmission
Unit size of an IP packet is $MTU = 64KB$. TCP lies on top of IP: to overcome
the unreliable aspect of IP, countermeasures should be adopted.

TCP layers communicate between themselves in terms of \emph{segments}. A
segment is a \emph{message between TCP layers}, and contains a \emph{TCP
header} and \--- eventually \--- data \emph{payload}. Payload can either be $0$
byte or carry some information useful for application layers. An important
property is that \emph{it must be small enough to fit in a single IP packet},
hence IP header + TCP segment size should be no greater than $64KB$.

A segment is thus composed by a IP header, whose payload is a TCP segment. The
TCP segment is composed by a TCP header, followed by eventual application data.
Usually, IP header size is usually $20$ bytes, as well as TCP header that is
$20$ bytes. The IP datagram can be greater up to $64KB$, with the first $40,50$
bytes reserved to headers.

Segments can carry portions of data (for instance, in a video stream many
segments should be sent to client in order to carry enough information and let
application layer reconstruct the video correctly).

In application layer, one application message could correspond to \emph{many
segments} in TCP layer, in \textbf{both} directions. In fact, at TCP level
multiple segments are usually required in order to send a single
application-level message.

Each TCP layer represents a connection as (<id>, <state>). The <id> is the
<IP-local, port-local, IP-remote, port-remote>, while the <state> refers to the
state of the TCP connection. Conceptually there is a single table storing both
<id> along with connection <state>.

IP addresses are extracted from the IP header, while port numbers are extracted
from TCP header. Packets are thus sorted accordingly. The connection <state>
includes information on the \emph{Maximum Segment Size} (MSS), which is the
maximum size of the \emph{data part} of a segment that the other part is
willing to achieve. The MSS is negotiated upon connection opening. This value
is, in practice, identical in both direction and is not arbitrary. In most
cases, there are only $2$ possible values for historical reasons:

\begin{itemize}
	\item on different networks (through internet), MSS is $536$ bytes (MTU=576),
		that is the maximum segment size that can fit in the smallest
		possible packet;
	\item on same network (ethernet), MSS is $1460$ bytes (MTU=1500), which
		corresponds to ethernet MTU minus the IP header and TCP header.
\end{itemize}

The core idea is that each segment must be sufficiently small to fit in one
packet along the full path, in order to prevent fragmentation.

TODO Add figure that recaps IP header + TCP header.

\section{Establishing a TCP Connection}

At the beginning of a TCP connection, $3$ segments are needed, while $2$ segments are needed to close it.

DNS -> To forge it, must change IP address to response AS WELL AS copying Transaction ID of request


\section{TCP Architecture}

TCP has many different implementations, depending mostly on chosen OS. Several
variants of its components are written, with many of them largely optional.

TCP works in segments. Suppose to be at the application level. Execution flow
at application level works independently and unpredictably with respect to the
TCP-level flow. When an application sends something, multiple TCP packages must
be exchanged. The sequence of bytes will be copied to a buffer (sliding window)
and the \texttt{send()} function is, for example, invoked \--- time in which a
segment is sent is \emph{unpredictable}, \emph{unrepeatable}.

Many events can provoke a transmission:

\begin{itemize}
	\item application invokes \texttt{send()};
	\item application invokes \texttt{receive()};
	\item TCP layer \emph{receives a segment};
	\item a \emph{timeout} occurs;
\end{itemize}

Each of the above will trigger a transmission either immediately or
\emph{withing a maximum predefined time} (in the case of a timeout, for
instance). When a TCP layer is touched from above or below, \textbf{it reacts
by transmitting a segment}.

Transmission may occur \emph{even if there is no useful data to transmit} (e.g.
the transmission buffer is empty) \-- in that case, a segment will only carry
the header.

Transmission may transmit a varying number of bytes, ranging from empty up to
bytes number \emph{larger than Maximum Segment Size} ($536$ in Internet
network, $1460$ for same Ethernet network). In that case, the payload must be
\emph{fragmented} before delivery, and multiple segments are delivered in sequence.
It happens that $2$ or $3$ segments are initially delivered before the
acknowledgement.

\begin{table}[ht]
\centering
\begin{tabular}{cc}
CPU Cycle & $0.3 ns$ \\
Main Memory Access (DRAM) & $120ns$ \\
SSD & 50-150 $\mu s$ \\
HHD & $10 ms$ \\
Internet SF to NY & $40ms$
\end{tabular}
\caption{Some interesting metrics.}\label{tab:SomeMetrics}
\end{table}
\bigskip

TCP starts sending slowly, increasing the exchange speed. Acceleration depends
on the timing of \emph{received} packets, by looking at the metrics of
confirmation packets from receiver.

\subsection{The \texttt{send()} system call}

\texttt{send()} is the system call that processes call to send data through the
network. The \texttt{send} function passes a memory buffer contained in
application space (address, legth), copies bytes from transmission memory
buffer (TX-buffer) in application space to memory byffer in TCP layer.

\begin{lstlisting}
public void write(byte[] b)
	throws IOException
\end{lstlisting}

Send is first invoked by application level. Buffer at application layer is then
copied to the TCP transmission buffer, to be sent immediately or later. New
invokations of \texttt{send()} will copy data in TCP buffer \textbf{after} the
data that is already present. 

\subsection{The \texttt{receive()} system call}

When data reaches the receiver, the data is copied into a receiving buffer
(RX-buffer). The receiver buffer is flushed only when the application invokes
\texttt{receive()}. The function \texttt{receive()} copies receiver buffer to
application buffer, receive copies without exceeding the size of the buffer (it
returns how many bytes are copied). Receive takes as argument also the number
of bytes to get from the TCP receiving buffer.

There are three possible cases:

\begin{itemize}
	\item if the receive buffer is empty, the application is suspended and
		the process is put to sleep;
	\item if more than \texttt{length} bytes are available, a
		\texttt{length} number of bytes is fetched;
	\item if less than \texttt{length} bytes are available, all available
		bytes are copied.
\end{itemize}

\subsection{Sending N bytes}

Suppose to send $N$ bytes with $K$ consecutive \texttt{send()} invocations. How
many segments will be exchanged? How many transmission events?

As a first approximation, the number of transmitted segments will roughly be
$$num = \frac{N}{MSS} + 1,$$ with the last segment $+1$ smaller than the
previous ones. Things, however, can be much more complex due to packet loss and
retransmissions.

Recall that the number per se is not predictable and not repeatable (TCP is
byte-oriented).

\section{Sequence numbers}

Since IP is \emph{unreliable} (packets can be lost, duplicated, or delivered in
different order from which they were sent), each data byte is implicitly
identified by a $32$ bit \textbf{sequence number}. The association is implicit
\--- the sender applies a sequence number to a segment, and the receiver uses
it to reconstruct the actual order of segments.

There are several sequence number. \texttt{snd.User} is the variable carrying
the value of the next byte the \textbf{application} will send.
\texttt{snd.Next} is the variable carrying the value of the next byte that the
\textbf{TCP layer} will transmit \--- its value is contained in the TCP header
(initial byte of the sequence, of course).

The sequence number of application level must be computed from other
information.

In short,

\begin{itemize}
	\item \texttt{snd.Next} is the boundary between transmitted data and
		yet-to-transmit data;
	\item \texttt{snd.User} is the boundary between in TX-buffer data (data
		sent by application) and not-yet-associated bytes.
\end{itemize}

From the receiver's point of view, there is a variable, \texttt{rcv.Next}, that
is the boundary between content of RX-buffer and not-yet-received data (right
boundary of the data currently in buffer). Only packets having expected
sequence number are collected and put in the buffer \--- however, if some
packet has new parts of information and sequence numbers not collected, they
will be collected and duplicated bytes are thrown away. There may be two
reasons for packet duplications: IP duplication, and TCP sender retransmission
because it thought it was lost. TCP stores packets in buffer until
acknowledgement has been received, since they could be retransmitted in the
immediate future.

\begin{itemize}
	\item \texttt{rcv.Next} points at the next byte that is not yet being
		received;
	\item \texttt{rcv.User} points to the next byte to be received by the
		application. After \texttt{receive()} invokation by the
		application, all delivered to the application bytes can now be
		deleted, since there are no retransmission needs. 
\end{itemize}

An important detail is that \textbf{sequence numbers are 32-bit integers}.
Therefore, there may be a \emph{wrap-around} (overflow-like behavior). TCP
should handle these comparisons accordingly.

\section{Handling duplicates and loss}

IP is an unreliable protocol. This means that \emph{packets can be loss}.
Necessary mechanisms are

\begin{itemize}
	\item \textbf{retransmission};
	\item \textbf{acknowledgement}, which is a kind of \emph{notification
		of receipt}, in order to be sure that the receiver has received
		all the data we sent them.
\end{itemize}

Acknowledgements is a mechanism that assures receipt of a message by
notifications. Every header of a segment contains the sequence number of
\texttt{snd.Next}. Every segment also \emph{carries an information regarding
the bytes that are received}: the \textbf{acknowledgement number}, which tracks
the state of the RX-buffer by the pointer \texttt{rcv.Next}. This way, having
both sequence number and acknowledgement number, one can successfully track the
state of a TCP connection. When sending a TCP segment, both sequence number and
acknowledgement number are sent, so that the receiver can reconstruct the state
of the sender RX-buffer.

A fifth variable is needed: \texttt{snd.Ack}, which \emph{points to the byte in
TX-buffer that are both transmitted and acknowledged}. This variable is only
increased upon receiving data (for instance, upon receiving a sequence with a
greater ACK number from the sender). Data before \texttt{snd.Ack} pointer can
safely be discarded. Acknowledgements are crucial to a TCP connection, in order
to guarantee \textbf{reliability} of a connection (TCP is connection-oriented).
Therefore, transmission is always necessary even if TX-buffer is empty. That
case, no payload will be transmitted, only information in header is sent
(increasing acknowledgement number). 

Data bytes between pointers \texttt{snd.Ack} and \texttt{snd.Next} is said to
be \emph{in flight} data. These bytes have been transmitted but not yet
acknowledged.

\section{Delayed Acknowledgement}

\emph{Delayed Acknowledgement} is a famous TCP algorithm. It is pretty
straightforward:

\begin{quote}
Upon receiving a segment, if delayed-ack timer $T$ has previously been set,
transmit immediately. Else, set the delayed-ack timer $T$ to a value.
\end{quote}

Delayed-ack timer value depends on the operating system:

\begin{itemize}
	\item RFC suggests $T = 500ms$;
	\item Windows has $T = 200ms$;
	\item Linux in general has $T = 40ms$;
	\item RHEL sets $T = 4ms$.
\end{itemize}

If there is not much data to transmit, it will be likely that the timer $T$
will expire. If the other part is sending a lot of data, the contrary will be
more likely to occur, breaking the awaiting.

The core idea is to minimize the number of segments to be sent. In fact, a
delay time $T$ assured to save sending some segments, a feature that
historically was of a crucial importance.

\section{Retransmissions}

The connection state includes three more variables:

\begin{itemize}
	\item a \textbf{retransmission timer};
	\item a \emph{variable that describes the duration of retransmission
		timer}, the \textbf{RTO};
	\item a \textbf{retransmission counter}.
\end{itemize}

The algorithm is as follows:

\begin{quote}
Upon transmitting segment S, the counter is cleared and set to $0$, with the
timer set to the RTO value. Upon receiving an ACK, \texttt{snd.Ack} is set to
the maximum value between \texttt{snd.Ack} and \texttt{segment.Ack}. If
\texttt{snd.Ack == snd.Next} the timer is switched off.

Upon timer expiring, the counter is incremented and if the counter has not yet
reached a \texttt{MAX\_COUNT} value, the segment is retransmitted. However, this
time the timer value is set to RTO but \texttt{RTO = 2 * RTO}. Only in-flight data
should be retransmitted (and all of it after timer expires). Basically, data
for which we are sure that it has been received, should not be retransmitted in
case the timer expires.

When counter reached \texttt{MAX\_COUNT} value, connection is closed.
\end{quote}

Windows closes connection after $5$ failed attempts, Linux after $15$.

It is simple to realise that there may be a lot of unnecessary retransmissions.
The timer can, for instance, run out too soon for the acknowledgement to reach
the sender. Unnecessary retransmissions are a waste of resources, a fundamental
problem. The reason could be one of those:

\begin{itemize}
	\item segments are lost;
	\item segments wich ACK are lost;
	\item RTO was set to a too small value.
\end{itemize}

Thus, RTO should be set to an appropriate value, since a too short value leads
to high overhead and possibly many unnecessary retransmissions, while a too
long value results in high latency and possibly a slow connection. RTO should
be set \textbf{dinamically}.

The RTO should be slightly greater than the \emph{RTT} (round-trip-time), and
it is an idea from Jacobson algorithm. This is of a crucial importance for TCP
to work.

Initial RTO value is heuristical, and varies from one OS to another. Linux and
Window start from same value, macOS use a different value, and so on.



\end{document}

